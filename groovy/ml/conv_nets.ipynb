{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a CNN to predict Reaction-Diffusion parameters from steady state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Select CPU/GPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the generated database\n",
    "folder = 'database'\n",
    "files = os.listdir(folder)\n",
    "\n",
    "images = []\n",
    "targets = []\n",
    "\n",
    "for file in files:\n",
    "    with open(f\"{folder}/{file}\", 'rb') as f:\n",
    "        images.append(pickle.load(f))\n",
    "    targets.append(np.asarray(file.split('.')[0].split('_')).astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the axes so that the components come first\n",
    "images = [np.swapaxes(image, 0, 2) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, Y):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx]), torch.from_numpy(self.Y[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "\n",
    "# Split the data into train, validation, test\n",
    "X_trv,   X_test, Y_trv,   Y_test = train_test_split(images, targets, train_size=0.8)\n",
    "X_train, X_val,  Y_train, Y_val  = train_test_split(images, targets, train_size=0.75)\n",
    "\n",
    "# Convert to Pytorch data loaders\n",
    "batch_size = 100\n",
    "training   = DataLoader(MyDataset(X_train, Y_train), batch_size=batch_size)\n",
    "validation = DataLoader(MyDataset(X_val,   Y_val),   batch_size=batch_size)\n",
    "test       = DataLoader(MyDataset(X_test,  Y_test),  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our CNN\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(2, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(100*100*2, 4)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.sig(self.fc(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fc4ab8aeec4b19b43f9d9ecaae3e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epochs', max=50.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train batches', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/182/mlindn/.conda/envs/phosphine-env/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([40, 1])) that is different to the input size (torch.Size([40, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation batches', max=1.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/182/mlindn/.conda/envs/phosphine-env/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([14, 1])) that is different to the input size (torch.Size([14, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train batches', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation batches', max=1.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train batches', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation batches', max=1.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train batches', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation batches', max=1.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train batches', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation batches', max=1.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train batches', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation batches', max=1.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train batches', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation batches', max=1.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6 out of 50 total.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test batches', max=1.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/182/mlindn/.conda/envs/phosphine-env/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([11, 1])) that is different to the input size (torch.Size([11, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "num_epochs = 50\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Model, loss, and optimizer\n",
    "cnn = CNN()\n",
    "cnn = cnn.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "validation_losses = []\n",
    "for epoch in tqdm(range(num_epochs), desc='Epochs', leave=False):\n",
    "\n",
    "    # Training loss\n",
    "    cnn.train()\n",
    "    for i, (images, targets) in enumerate(tqdm(training, desc='Train batches', leave=False)):\n",
    "\n",
    "        images, targets = images.to(device, dtype=torch.float), targets.to(device, dtype=torch.float)\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loss\n",
    "    cnn.eval()\n",
    "    epoch_losses = []\n",
    "    for i, (images, targets) in enumerate(tqdm(validation, desc='Validation batches', leave=False)):\n",
    "\n",
    "        images, targets = images.to(device, dtype=torch.float), targets.to(device, dtype=torch.float)\n",
    "        outputs = cnn(images)\n",
    "        loss_val = criterion(outputs, targets).item()\n",
    "        epoch_losses.append(loss_val)\n",
    "\n",
    "    # Early stopping\n",
    "    patience = 7\n",
    "    validation_losses.append(np.mean(epoch_losses))\n",
    "    if len(validation_losses) >= patience and np.argmin(validation_losses[-patience:]) == 0:\n",
    "        print(f\"Early stopping at epoch {epoch} out of {num_epochs} total.\")\n",
    "        break\n",
    "\n",
    "else:\n",
    "    print(f\"No early stopping used. Completed {num_epochs} epochs.\")\n",
    "\n",
    "# Test set\n",
    "cnn.eval()\n",
    "test_losses = []\n",
    "for i, (images, targets) in enumerate(tqdm(test, desc='Test batches', leave=False)):\n",
    "\n",
    "    images, targets = images.to(device, dtype=torch.float), targets.to(device, dtype=torch.float)\n",
    "    outputs = cnn(images)\n",
    "    loss_val = criterion(outputs, targets).item()\n",
    "    test_losses.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the training curve\n",
    "plt.plot(np.arange(len(validation_losses)) + 1, validation_losses, label='Validation Loss')\n",
    "plt.axhline(np.mean(test_losses), c='r', linestyle='--', label='Test Loss')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('MSE loss')\n",
    "plt.xlim([1, len(validation_losses)])\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# View 2 examples from the test set\n",
    "plt.subplot(121)\n",
    "plt.imshow(images.cpu()[0,0,:,:], cmap='gist_gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(images.cpu()[1,0,:,:], cmap='gist_gray')\n",
    "\n",
    "print('Left image true parameters:', targets.cpu().numpy()[0])\n",
    "print('Left image CNN predictions:', outputs.cpu().detach().numpy()[0])\n",
    "print()\n",
    "print('Right image true parameters:', targets.cpu().numpy()[1])\n",
    "print('Right image CNN predictions:', outputs.cpu().detach().numpy()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the image inputs\n",
    "def sanitize(img):\n",
    "    \"\"\"\n",
    "    Convert a jpeg into an 100x100, 2 component image.\n",
    "    \"\"\"\n",
    "    # Resize image\n",
    "    min_length = min(img.size)\n",
    "    img = img.crop((0, 0, min_length, min_length))\n",
    "    img = img.resize((100, 100))\n",
    "\n",
    "    # Convert to 2-channel pixel array\n",
    "    return np.asarray([[r, 255-g] for r, g, b in img.getdata()]).reshape(100, 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble images\n",
    "labels = ['giraffe', 'leopard', 'zebra']\n",
    "images = {label: [sanitize(Image.open(image)) for image in glob(f\"patterns/{label}_*.jpg\")] for label in labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate 2-component image\n",
    "img = images['zebra'][0]\n",
    "plt.subplot(121)\n",
    "plt.imshow(img[:,:,0], cmap='gist_gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img[:,:,1], cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
